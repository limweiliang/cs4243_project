{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add0f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "# import utils\n",
    "\n",
    "classes = {\"Black-naped Oriole\": 0,\n",
    "              \"Brown-throated Sunbird\": 1,\n",
    "              \"Collared Kingfisher\": 2, \n",
    "              \"Javan Myna\": 3, \n",
    "              \"Olive-backed Sunbird\": 4, \n",
    "              \"Pink-necked Green Pigeon\": 5, \n",
    "              \"Spotted Dove\": 6, \n",
    "              \"Striated Heron\": 7, \n",
    "              \"White-breasted Waterhen\": 8, \n",
    "              \"Yellow-vented Bulbul\": 9}\n",
    "label_folder_name = 'labels/bboxes_after_split/'\n",
    "dataset_folder_name = 'Cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af85cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_label(csv):\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "\n",
    "    all_data = None\n",
    "    all_label = torch.Tensor()\n",
    "    labels = []\n",
    "\n",
    "    df = pd.read_csv(label_folder_name + csv)\n",
    "    df = df.drop_duplicates(subset=['image_name'])\n",
    "    train_filenames = df['image_name']\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['image_name']\n",
    "        \n",
    "        # Remove transparency layer\n",
    "        img = Image.open(dataset_folder_name + filename).convert('RGBA')\n",
    "        background = Image.new('RGBA', img.size, (255,255,255))\n",
    "        alpha_composite = Image.alpha_composite(background, img)\n",
    "        img = alpha_composite.convert('RGB')\n",
    "        \n",
    "        data = convert_tensor(img)        \n",
    "        data = torch.unsqueeze(data, 0)\n",
    "\n",
    "        if all_data == None:\n",
    "            all_data = data\n",
    "        else:\n",
    "            all_data = torch.cat((all_data, data), 0)\n",
    "\n",
    "        label_name = row['label']\n",
    "        label_id = classes[label_name]\n",
    "        labels.append(label_id)\n",
    "\n",
    "    all_label = torch.Tensor(labels).long()\n",
    "    return all_data, all_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff3c5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([700, 3, 224, 224])\n",
      "torch.Size([700])\n",
      "torch.LongTensor\n",
      "torch.Size([150, 3, 224, 224])\n",
      "torch.Size([150])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = load_data_and_label('train_bbs.csv')\n",
    "print(train_data.size())\n",
    "print(train_label.size())\n",
    "print(train_label.type())\n",
    "\n",
    "val_data, val_label = load_data_and_label('val_bbs.csv')\n",
    "print(val_data.size())\n",
    "print(val_label.size())\n",
    "print(val_label.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a2481a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(scores, labels):\n",
    "    bs = scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim = 1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches = indicator.sum()\n",
    "    \n",
    "    return 1 - num_matches.float() / bs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "394c84bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_layer_net(\n",
      "  (linear_layer): Linear(in_features=150528, out_features=10, bias=False)\n",
      ")\n",
      " \n",
      "epoch= 0  time= 0.45108795166015625  loss= 727.3730938434601  error= 88.28571370669773 percent lr= 0.05\n",
      "test error  =  85.99999944368997 percent\n",
      " \n",
      "epoch= 10  time= 4.8259477615356445  loss= 114.09992032732282  error= 49.999999914850505 percent lr= 0.03333333333333333\n",
      "test error  =  88.66666595141093 percent\n",
      " \n",
      "epoch= 20  time= 9.18831205368042  loss= 9.049389348564103  error= 14.5714294058936 percent lr= 0.014814814814814815\n",
      "test error  =  82.66666571299235 percent\n",
      " \n",
      "epoch= 30  time= 13.54047679901123  loss= 1.184341823510139  error= 3.8571432658604214 percent lr= 0.006584362139917695\n",
      "test error  =  75.99999984105428 percent\n",
      " \n",
      "epoch= 40  time= 17.900568962097168  loss= 0.40374792305843543  error= 1.7142859527042933 percent lr= 0.0029263831732967535\n",
      "test error  =  79.3333331743876 percent\n",
      " \n",
      "epoch= 50  time= 22.27194094657898  loss= 0.1689044158476295  error= 0.7142858845846993 percent lr= 0.001300614743687446\n",
      "test error  =  79.9999996026357 percent\n",
      " \n",
      "epoch= 60  time= 26.765211820602417  loss= 0.1064211656702417  error= 1.1428573301860265 percent lr= 0.0005780509971944203\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 70  time= 31.2547550201416  loss= 0.07185715517742765  error= 0.5714287076677596 percent lr= 0.00025691155430863124\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 80  time= 35.911972761154175  loss= 0.064139486939422  error= 1.000000238418579 percent lr= 0.00011418291302605833\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 90  time= 40.54048681259155  loss= 0.06001635099300765  error= 0.7142858845846993 percent lr= 5.074796134491482e-05\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 100  time= 45.36883091926575  loss= 0.05847627027048341  error= 0.5714287076677596 percent lr= 2.255464948662881e-05\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 110  time= 49.98170804977417  loss= 0.057830682301974634  error= 0.7142858845846993 percent lr= 1.0024288660723916e-05\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 120  time= 54.5470757484436  loss= 0.05754243993777892  error= 0.7142858845846993 percent lr= 4.455239404766185e-06\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 130  time= 59.09402084350586  loss= 0.057412574408952415  error= 0.7142858845846993 percent lr= 1.9801064021183043e-06\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 140  time= 63.57099390029907  loss= 0.057354581713093974  error= 0.7142858845846993 percent lr= 8.800472898303575e-07\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 150  time= 68.05225801467896  loss= 0.05732871084026933  error= 0.7142858845846993 percent lr= 3.911321288134922e-07\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 160  time= 72.54128575325012  loss= 0.05731720173140827  error= 0.7142858845846993 percent lr= 1.738365016948854e-07\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 170  time= 76.94487881660461  loss= 0.05731254945531989  error= 0.7142858845846993 percent lr= 7.726066741994908e-08\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 180  time= 81.4011549949646  loss= 0.057309943671352365  error= 0.7142858845846993 percent lr= 3.4338074408866255e-08\n",
      "test error  =  80.66666603088379 percent\n",
      " \n",
      "epoch= 190  time= 85.90103888511658  loss= 0.05730884221898224  error= 0.7142858845846993 percent lr= 1.5261366403940557e-08\n",
      "test error  =  80.66666603088379 percent\n"
     ]
    }
   ],
   "source": [
    "class one_layer_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(one_layer_net , self).__init__()\n",
    "        self.linear_layer = nn.Linear( input_size, output_size , bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        scores = self.linear_layer(x)\n",
    "        return scores\n",
    "    \n",
    "net = one_layer_net(3 * 224 * 224, 10)\n",
    "\n",
    "print(net)\n",
    "# utils.display_num_param(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 10\n",
    "\n",
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for i in range(0, 150, batch_size):\n",
    "\n",
    "        minibatch_data =  val_data[i : i + batch_size]\n",
    "        minibatch_label = val_label[i : i + batch_size]\n",
    "\n",
    "        inputs = minibatch_data.view(batch_size, 3 * 224 * 224)\n",
    "\n",
    "        scores = net(inputs) \n",
    "\n",
    "        error = get_error(scores , minibatch_label)\n",
    "\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "\n",
    "    total_error = running_error / num_batches\n",
    "    print( 'test error  = ', total_error*100 ,'percent')\n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "lr = 0.05 # initial learning rate\n",
    "\n",
    "for epoch in range(200):\n",
    "    \n",
    "    # learning rate strategy : divide the learning rate by 1.5 every 10 epochs\n",
    "    if epoch % 5 == 0 and epoch > 5: \n",
    "        lr = lr / 1.5\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    optimizer=torch.optim.SGD(net.parameters() , lr = lr)\n",
    "        \n",
    "    running_loss, running_error, num_batches = 0, 0, 0\n",
    "    \n",
    "    shuffled_indices = torch.randperm(700)\n",
    " \n",
    "    for count in range(0, 700, batch_size):\n",
    "        \n",
    "        # forward and backward pass\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        indices = shuffled_indices[count : count + batch_size]\n",
    "        minibatch_data = train_data[indices]\n",
    "        minibatch_label = train_label[indices]\n",
    "\n",
    "        inputs = minibatch_data.view(batch_size, 3 * 224 * 224)\n",
    "\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # compute some stats\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "               \n",
    "        error = get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches += 1\n",
    "    \n",
    "    \n",
    "    # once the epoch is finished we divide the \"running quantities\"\n",
    "    # by the number of batches\n",
    "    \n",
    "    total_loss = running_loss / num_batches\n",
    "    total_error = running_error / num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "    \n",
    "    # every 10 epoch we display the stats \n",
    "    # and compute the error rate on the test set  \n",
    "    \n",
    "    if epoch % 10 == 0 : \n",
    "    \n",
    "        print(' ')\n",
    "        \n",
    "        print('epoch=',epoch, ' time=', elapsed_time,\n",
    "              ' loss=', total_loss , ' error=', total_error*100 ,'percent lr=', lr)\n",
    "        \n",
    "        eval_on_test_set()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net( im.view(1,784)) \n",
    "probs= torch.softmax(scores, dim=1)\n",
    "utils.show_prob_mnist(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5e1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
